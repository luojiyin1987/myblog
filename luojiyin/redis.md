1.  Memcached 支持value类型为String类型
Redis 支持的value类型包括String 哈希表 列表 集合 
Redis 能够在实际业务场景中得到广泛的应用，得益于支持多样化类型的value

2. 索引的类型有很多， 常见的有哈希表 B+树   字典树，不同的索引结构在性能 空间消耗
并发控制有不同的特征， Memcached和Redis采用哈希表作为key-value 索引
而 RocksDB采用跳表作为内存中的 key-value的索引

3. 内存键值数据库中使用哈希表作为索引， 很大一部分原因在于，内存的高性能访问特性很好地与
哈希表O(1)的操作复杂度相匹配

4. Redis主要通过网络框架访问，而不再是动态库， 这也是Redis可以作为基础性的网络服务进行访问

5. Redis数据模型的value 类型很丰富, 因此也带来了更多的操作接口，例如面向列表的LPUSH/LPOP
面向集合的SADD/SREM 等， 

6. Redis持久化支持两种方式   日志(AOF)和快照(RDB) 

7. Redis 6种数据结构  string -->简单动态字符串   List -->双向链表(或 压缩列表)
Hash --> 哈希表(压缩列表)   Sorted Set -->压缩列表(或 跳表)   Set -->整数数组(哈希表  )

8. 为什么哈希表操作会变慢， 当往Redis中写入了大量的数据后，可能出现哈希表冲突问题和rehash操作带来的操作阻塞
Redis 解决哈希冲突的方式，就是链式哈希， 指同一个哈希通中的多个元素用一个链表保存，它们之间依次用指针连接
这里存在一个问题，哈希冲突链上的元素只能通过指针逐一查找再操作
导致元素查找耗时长， Redis会对哈希表作rehash操作， 增加现有的哈希桶数量， 让entry元素分散在更多的桶中，减少桶中元素个数
其实为了更高效的操作， Redis默认使用了两个全局哈希表，哈希表1  哈希表2 
开始的时候  当插入数据时候 默认使用哈希表1  哈希表2 并没有被分配空间
当数据增多时， Redis开始执行rehash, 这个过错分为三步 
1 给哈希表2 分配更大的空间  ，例如是当前哈希表1 两倍
2 把哈希表1中的数据重新映射并拷贝到哈希表2 中
3 释放哈希表1的空间

如果一次性把哈希表1 中的数据都迁移完， 会造成Redis线程阻塞， 无法提供服务，
为避免这个问题， Redis采用渐进性 rehash
简单来说在第二步拷贝数据时， 每请求一个请求时， 从哈希表1 中的第一个索引位置开始，顺便把这个位置上的所有entries
拷贝到哈希表2 中， 等待下一个请求时， 再顺便拷贝哈希表1中下一个索引位置的entries 

9. Sorted Set也采用了O(logN)复杂度的跳表， 不过集合类型的范围操作，因为要遍历底层数据， 复杂度通常时O(N) 可以用
其他命令代替， 比如用SCAN

10. List  有两种底层实现结构:  双向链表和压缩列表复杂度都是O（N） 它们的POP/PUSH效率很高 主要用于FIFO队列场景
而不是可以随机读写的集合。

11. Redis单线程是指 Redis的网络IO 和键值对读写是由一个线程完成的，这也是Redis对外提供键值对存储服务的主要流程
但Redis的其他功能 比如持久化 异步删除  集群数据同步等  其实由额外的线程执行的

12. 并发访问控制一直是多线程开发的一个难点。 、

13. 一方面Redis大部分操作是在内存上完成， 再加上它采用了高效的数据结构， 
另一方面， 就是Redis采用了多路复用机制，使再网络IO操作中能并发大量的客户请求

14. 小心AOF文件过大带来的性能问题  -->AOF重写机制
重写实现 多变一，把旧文件中的多个命令， 重写后变成一条命令
AOF日志由主线程写回不同， 重写过程是由后台线程 bgrewriteaof 来完成，
避免阻塞主线程， 导致数据库性能下降  
一个拷贝  两处日志
一个拷贝”就是指，每次执行重写时，主线程 fork 出后台的 bgrewriteaof 子进程。
此时，fork 会把主线程的内存拷贝一份给 bgrewriteaof 子进程，这里面就包含了数据库的最新数据。
然后，bgrewriteaof 子进程就可以在不影响主线程的情况下，逐一把拷贝的数据写成操作，记入重写日志。
“两处日志”又是什么呢？因为主线程未阻塞，仍然可以处理新来的操作。此时，如果有写操作，第一处日志就是指正在使用的 AOF 日志，Redis 会把这个操作写到它的缓冲区。这样一来，即使宕机了，这个 AOF 日志的操作仍然是齐全的，可以用于恢复。

问题1，Redis采用fork子进程重写AOF文件时，潜在的阻塞风险包括：fork子进程 和 AOF重写过程中父进程产生写入的场景，下面依次介绍。

a、fork子进程，fork这个瞬间一定是会阻塞主线程的（注意，fork时并不会一次性拷贝所有内存数据给子进程，老师文章写的是拷贝所有内存数据给子进程，我个人认为是有歧义的），fork采用操作系统提供的写实复制(Copy On Write)机制，就是为了避免一次性拷贝大量内存数据给子进程造成的长时间阻塞问题，但fork子进程需要拷贝进程必要的数据结构，其中有一项就是拷贝内存页表（虚拟内存和物理内存的映射索引表），这个拷贝过程会消耗大量CPU资源，拷贝完成之前整个进程是会阻塞的，阻塞时间取决于整个实例的内存大小，实例越大，内存页表越大，fork阻塞时间越久。拷贝内存页表完成后，子进程与父进程指向相同的内存地址空间，也就是说此时虽然产生了子进程，但是并没有申请与父进程相同的内存大小。那什么时候父子进程才会真正内存分离呢？“写实复制”顾名思义，就是在写发生时，才真正拷贝内存真正的数据，这个过程中，父进程也可能会产生阻塞的风险，就是下面介绍的场景。

b、fork出的子进程指向与父进程相同的内存地址空间，此时子进程就可以执行AOF重写，把内存中的所有数据写入到AOF文件中。但是此时父进程依旧是会有流量写入的，如果父进程操作的是一个已经存在的key，那么这个时候父进程就会真正拷贝这个key对应的内存数据，申请新的内存空间，这样逐渐地，父子进程内存数据开始分离，父子进程逐渐拥有各自独立的内存空间。因为内存分配是以页为单位进行分配的，默认4k，如果父进程此时操作的是一个bigkey，重新申请大块内存耗时会变长，可能会产阻塞风险。另外，如果操作系统开启了内存大页机制(Huge Page，页面大小2M)，那么父进程申请内存时阻塞的概率将会大大提高，所以在Redis机器上需要关闭Huge Page机制。Redis每次fork生成RDB或AOF重写完成后，都可以在Redis log中看到父进程重新申请了多大的内存空间。

问题2，AOF重写不复用AOF本身的日志，一个原因是父子进程写同一个文件必然会产生竞争问题，控制竞争就意味着会影响父进程的性能。二是如果AOF重写过程中失败了，那么原本的AOF文件相当于被污染了，无法做恢复使用。所以Redis AOF重写一个新文件，重写失败的话，直接删除这个文件就好了，不会对原先的AOF文件产生影响。等重写完成之后，直接替换旧文件即可。

15. RDB 是记录某一时刻的数据， 并不是操作，再数据恢复时，我们可以直接用RDB文件读入内存 很快恢复
但不时最优选。 两个问题
1 对比那些数据做快照，这关系到快照的执行效率问题
2 作快照时， 数据还能被增删改吗？ 
为了所有数据的可靠性 它执行的时全量快照    两个命令生成RDB文件， 分别时save 和 bgsave

混合使用AOF和内存快照的   内存快照在一定频率执行， 在两个快照之间，使用AOF日志记录所有命令操作


15. 消息队列在存取消息时   有三个条件
1 消息保序
2 重复消息处理
3 消息可靠性保证

基于List的消息队列解决
为了解决消费者不停调用RPOP, Redis提供了BRPOP命令，阻塞式读取，客户端没读到队列数据时，自动阻塞，直到有新的数据写入队列
再开始读取新的数据
为了解决重复消息的问题， 给每一消息提供全局唯一的ID号， 消费者要把已经处理的消息记录下  进行判断
为了存留消息， 可以使用List中的 BRPOPLPUSH 命令, 让消费者程序从一个List中读取消息， 同时Redis再把这个消息插入到另一个List
留存

从Redis 5.0提供Streams数据类型， 它支持消费组形式的消息读取， 提高消息处理能力

如果一个生产者发送给消息队列的消息，需要被多个消费者进行读取和处理，你会使用Redis的什么数据类型来解决这个问题？

这种情况下，只能使用Streams数据类型来解决。使用Streams数据类型，创建多个消费者组，就可以实现同时消费生产者的数据。每个消费者组内可以再挂多个消费者分担读取消息进行消费，消费完成后，各自向Redis发送XACK，标记自己的消费组已经消费到了哪个位置，而且消费组之间互不影响。

另外，老师在介绍使用List用作队列时，为了保证消息可靠性，使用BRPOPLPUSH命令把消息取出的同时，还把消息插入到备份队列中，从而防止消费者故障导致消息丢失。

这种情况下，还需要额外做一些工作，也就是维护这个备份队列：每次执行BRPOPLPUSH命令后，因为都会把消息插入一份到备份队列中，所以当消费者成功消费取出的消息后，最好把备份队列中的消息删除，防止备份队列存储过多无用的数据，导致内存浪费。

这篇文章主要是讲消息队列的使用，借这个机会，也顺便总结一下使用消息队列时的注意点：

在使用消息队列时，重点需要关注的是如何保证不丢消息？

那么下面就来分析一下，哪些情况下，会丢消息，以及如何解决？

1、生产者在发布消息时异常：

a) 网络故障或其他问题导致发布失败（直接返回错误，消息根本没发出去）
b) 网络抖动导致发布超时（可能发送数据包成功，但读取响应结果超时了，不知道结果如何）

情况a还好，消息根本没发出去，那么重新发一次就好了。但是情况b没办法知道到底有没有发布成功，所以也只能再发一次。所以这两种情况，生产者都需要重新发布消息，直到成功为止（一般设定一个最大重试次数，超过最大次数依旧失败的需要报警处理）。这就会导致消费者可能会收到重复消息的问题，所以消费者需要保证在收到重复消息时，依旧能保证业务的正确性（设计幂等逻辑），一般需要根据具体业务来做，例如使用消息的唯一ID，或者版本号配合业务逻辑来处理。

2、消费者在处理消息时异常：

也就是消费者把消息拿出来了，但是还没处理完，消费者就挂了。这种情况，需要消费者恢复时，依旧能处理之前没有消费成功的消息。使用List当作队列时，也就是利用老师文章所讲的备份队列来保证，代价是增加了维护这个备份队列的成本。而Streams则是采用ack的方式，消费成功后告知中间件，这种方式处理起来更优雅，成熟的队列中间件例如RabbitMQ、Kafka都是采用这种方式来保证消费者不丢消息的。

3、消息队列中间件丢失消息

上面2个层面都比较好处理，只要客户端和服务端配合好，就能保证生产者和消费者都不丢消息。但是，如果消息队列中间件本身就不可靠，也有可能会丢失消息，毕竟生产者和消费这都依赖它，如果它不可靠，那么生产者和消费者无论怎么做，都无法保证数据不丢失。

a) 在用Redis当作队列或存储数据时，是有可能丢失数据的：一个场景是，如果打开AOF并且是每秒写盘，因为这个写盘过程是异步的，Redis宕机时会丢失1秒的数据。而如果AOF改为同步写盘，那么写入性能会下降。另一个场景是，如果采用主从集群，如果写入量比较大，从库同步存在延迟，此时进行主从切换，也存在丢失数据的可能（从库还未同步完成主库发来的数据就被提成主库）。总的来说，Redis不保证严格的数据完整性和主从切换时的一致性。我们在使用Redis时需要注意。

b) 而采用RabbitMQ和Kafka这些专业的队列中间件时，就没有这个问题了。这些组件一般是部署一个集群，生产者在发布消息时，队列中间件一般会采用写多个节点+预写磁盘的方式保证消息的完整性，即便其中一个节点挂了，也能保证集群的数据不丢失。当然，为了做到这些，方案肯定比Redis设计的要复杂（毕竟是专们针对队列场景设计的）。

综上，Redis可以用作队列，而且性能很高，部署维护也很轻量，但缺点是无法严格保数据的完整性（个人认为这就是业界有争议要不要使用Redis当作队列的地方）。而使用专业的队列中间件，可以严格保证数据的完整性，但缺点是，部署维护成本高，用起来比较重。

所以我们需要根据具体情况进行选择，如果对于丢数据不敏感的业务，例如发短信、发通知的场景，可以采用Redis作队列。如果是金融相关的业务场景，例如交易、支付这类，建议还是使用专业的队列中间件。


是否可以采用服务熔断、服务降级、请求限流的方法来应对缓存穿透问题？

我觉得需要区分场景来看。

如果缓存穿透的原因是恶意攻击，攻击者故意访问数据库中不存在的数据。这种情况可以先使用服务熔断、服务降级、请求限流的方式，对缓存和数据库层增加保护，防止大量恶意请求把缓存和数据库压垮。在这期间可以对攻击者进行防护，例如封禁IP等操作。

如果缓存穿透的原因是，业务层误操作把数据从缓存和数据库都删除了，如果误删除的数据很少，不会导致大量请求压到数据库的情况，那么快速恢复误删的数据就好了，不需要使用服务熔断、服务降级、请求限流。如果误操作删除的数据范围比较广，导致大量请求压到数据库层，此时使用服务熔断、服务降级、请求限流的方法来应对是有帮助的，使用这些方法先把缓存和数据库保护起来，然后使用备份库快速恢复数据，在数据恢复期间，这些保护方法可以为数据库恢复提供保障。

还有一种缓存穿透的场景，我们平时会遇到的，和大家分享一下。

对于一个刚上线的新业务模块，如果还没有用户在这个模块内产生业务数据，当用户需要查询这个业务模块自己的数据时，由于缓存和数据库都没有这个用户的数据，此时也会产生缓存穿透，但这种场景不像误删数据和恶意攻击那样，而是属于正常的用户行为。

这种场景采用服务熔断、服务降级、请求限流的方式就没有任何意义了，反而会影响正常用户的访问。这种场景只能使用缓存回种空值、布隆过滤器来解决。

可见，服务熔断、服务降级、请求限流的作用是，当系统内部发生故障或潜在问题时，为了防止系统内部的问题进一步恶化，所以会采用这些方式对系统增加保护，待系统内部故障恢复后，可以依旧继续对外提供服务，这些方法属于服务治理的范畴，在任何可能导致系统故障的场景下，都可以选择性配合使用。

另外，关于文章所讲的由于“Redis缓存实例发生故障宕机”导致缓存雪崩的问题，我觉得一个可以优化的方案是，当Redis实例故障宕机后，业务请求可以直接返回错误，没必要再去请求数据库了，这样就不会导致数据库层压力变大。当然，最好的方式还是Redis部署主从集群+哨兵，主节点宕机后，哨兵可以及时把从节点提升为主，继续提供服务。

关于布隆过滤器的使用，还有几点和大家分享。

1、布隆过滤器会有误判：由于采用固定bit的数组，使用多个哈希函数映射到多个bit上，有可能会导致两个不同的值都映射到相同的一组bit上。虽然有误判，但对于业务没有影响，无非就是还存在一些穿透而已，但整体上已经过滤了大多数无效穿透请求。

2、布隆过滤器误判率和空间使用的计算：误判本质是因为哈希冲突，降低误判的方法是增加哈希函数 + 扩大整个bit数组的长度，但增加哈希函数意味着影响性能，扩大数组长度意味着空间占用变大，所以使用布隆过滤器，需要在误判率和性能、空间作一个平衡，具体的误判率是有一个计算公式可以推导出来的（比较复杂）。但我们在使用开源的布隆过滤器时比较简单，通常会提供2个参数：预估存入的数据量大小、要求的误判率，输入这些参数后，布隆过滤器会有自动计算出最佳的哈希函数数量和数组占用的空间大小，直接使用即可。

3、布隆过滤器可以放在缓存和数据库的最前面：把Redis当作布隆过滤器时（4.0提供了布隆过滤器模块，4.0以下需要引入第三方库），当用户产生业务数据写入缓存和数据库后，同时也写入布隆过滤器，之后当用户访问自己的业务数据时，先检查布隆过滤器，如果过滤器不存在，就不需要查询缓存和数据库了，可以同时降低缓存和数据库的压力。

4、Redis实现的布隆过滤器bigkey问题：Redis布隆过滤器是使用String类型实现的，存储的方式是一个bigkey，建议使用时单独部署一个实例，专门存放布隆过滤器的数据，不要和业务数据混用，否则在集群环境下，数据迁移时会导致Redis阻塞问题。

